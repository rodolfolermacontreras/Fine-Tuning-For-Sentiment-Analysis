{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b4a723a-dc2d-4016-9b04-cd1fdae77c89",
   "metadata": {},
   "source": [
    "# Capstone Project: Supervised Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6492b8e-1131-4ad8-82df-bd9c72826693",
   "metadata": {},
   "source": [
    "## Data ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d9770b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import emoji\n",
    "import re\n",
    "from html import unescape\n",
    "from emoji import demojize\n",
    "from IPython.display import display, Markdown\n",
    "import numpy as np\n",
    "from html import unescape\n",
    "\n",
    "# Modeling libraries\n",
    "from langdetect import detect\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from gensim.models import Word2Vec, FastText\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "import community as community_louvain\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Others\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "import os\n",
    "from joblib import dump\n",
    "\n",
    "\n",
    "# Suppress only UndefinedMetricWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb07a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df_original = pd.read_csv('sample_duo_data.csv')\n",
    "df_original['Update'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f765e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7e2de6-6778-4d3a-b0dd-cac95f27e3a8",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b4dd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176c8199-2d56-4ad5-969e-1596b7ae0685",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = df.columns\n",
    "for i in column_names:\n",
    "    x = len(df[i].unique())\n",
    "    print('Count of Unique Values for ' + str(i))\n",
    "    print(x)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861faf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display the body text as Markdown formatted text\n",
    "def display_as_paragraph(index, df=df, column_name='Body'):\n",
    "    \"\"\"\n",
    "    Display the text from the specified index in the given DataFrame as a formatted paragraph.\n",
    "\n",
    "    Parameters:\n",
    "    - index: int\n",
    "        The index of the row in the DataFrame to display.\n",
    "    - df: pandas.DataFrame, optional\n",
    "        The DataFrame containing the text data. Default is the global variable `df`.\n",
    "    - column_name: str, optional\n",
    "        The name of the column in the DataFrame containing the text data. Default is 'Body'.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    body_text = df.loc[index, column_name]\n",
    "    # Convert newlines into Markdown line breaks for better readability\n",
    "    formatted_text = body_text.replace('<br>', '\\n\\n')\n",
    "    display(Markdown(formatted_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2752a0",
   "metadata": {},
   "source": [
    "## Data Partitioning \n",
    "In preparation for labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5199db70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting index as a column\n",
    "df['Original Index'] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76250307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a reference DataFrame\n",
    "df_reference = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd5c7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now to remove duplicates while keeping the reference info, we first need to sort by 'Body' to ensure consistency\n",
    "df.sort_values(by='Body', inplace=True)\n",
    "\n",
    "# Dropping duplicates based on 'Body' and keeping the first occurrence\n",
    "df_clean = df.drop_duplicates(subset=['Body'], keep='first').reset_index(drop=True)\n",
    "df_clean['split_index'] = df_clean.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e210495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the label data \n",
    "df_label = pd.read_csv('Final_Label_Data.csv')\n",
    "df_deduplicated = pd.merge(df_clean, df_label, left_on='split_index', right_on='data_row.global_key', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77da28ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = [\n",
    "'attachments',\n",
    "'metadata_fields',\n",
    "'data_row.id',\n",
    "'data_row.details.dataset_id',\n",
    "'data_row.details.dataset_name',\n",
    "'data_row.details.created_at',\n",
    "'data_row.details.updated_at',\n",
    "'data_row.details.last_activity_at',\n",
    "'data_row.details.created_by',\n",
    "'media_attributes.mime_type',\n",
    "'projects.clsqaik7009uu07wselyi44w5.name',\n",
    "'projects.clsqaik7009uu07wselyi44w5.labels',\n",
    "'projects.clsqaik7009uu07wselyi44w5.project_details.ontology_id',\n",
    "'projects.clsqaik7009uu07wselyi44w5.project_details.task_name',\n",
    "'projects.clsqaik7009uu07wselyi44w5.project_details.batch_id',\n",
    "'projects.clsqaik7009uu07wselyi44w5.project_details.batch_name',\n",
    "'projects.clsqaik7009uu07wselyi44w5.project_details.workflow_status',\n",
    "'projects.clsqaik7009uu07wselyi44w5.project_details.priority',\n",
    "'projects.clsqaik7009uu07wselyi44w5.project_details.consensus_expected_label_count',\n",
    "'projects.clsqaik7009uu07wselyi44w5.project_details.workflow_history',\n",
    "'projects.clsqaik7009uu07wselyi44w5.project_details.selected_label_id'\n",
    "]\n",
    "\n",
    "# To modify the original DataFrame\n",
    "df_deduplicated.drop(columns=columns_to_remove, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befb4c53-61f1-4ef1-b4e5-f2fa827c476c",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a12908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pattern to match all emojis\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "                           u\"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "                           u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "                           u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "                           u\"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "                           u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "                           u\"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "                           u\"\\U000024C2-\\U0001F251\"  # Enclosed characters\n",
    "                           u\"⏭\"  # Additional symbols identified in your text\n",
    "                           u\"↪\"  # Additional symbols identified in your text\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "\n",
    "# Function to extract emojis from a string using regex\n",
    "def extract_emojis(s):\n",
    "    \"\"\"\n",
    "    Extracts emojis from a given string.\n",
    "\n",
    "    Args:\n",
    "        s (str): The input string from which emojis will be extracted.\n",
    "\n",
    "    Returns:\n",
    "        str: A space-separated string containing all the emojis found in the input string.\n",
    "             If the input is not a string, an empty string is returned.\n",
    "    \"\"\"\n",
    "    if isinstance(s, str):\n",
    "        return ' '.join(emoji_pattern.findall(s))\n",
    "    else:\n",
    "        return ''  # Return empty string if the input is not a string\n",
    "\n",
    "# Function to translate emojis to words and ensure spaces around them\n",
    "def translate_emojis(text):\n",
    "    \"\"\"\n",
    "    Translates emojis in the given text to their corresponding words.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to be translated.\n",
    "\n",
    "    Returns:\n",
    "        str: The translated text with emojis replaced by words.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text  # Return the original value if it's not a string\n",
    "    \n",
    "    def replace_with_words(match):\n",
    "        # Translate emoji to words\n",
    "        emoji_word = demojize(match.group(0), delimiters=(\" \", \" \"))\n",
    "        # Replace underscores with spaces and enclose in parentheses\n",
    "        emoji_word_clean = \" (\" + emoji_word.replace(\"_\", \" \").strip() + \") \"\n",
    "        return emoji_word_clean\n",
    "    \n",
    "    return emoji_pattern.sub(replace_with_words, text)\n",
    "\n",
    "# Decoding Emojis\n",
    "def decode_emojis(text):\n",
    "    \"\"\"\n",
    "    Decode emojis in the given text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to decode emojis from.\n",
    "\n",
    "    Returns:\n",
    "        str: The text with emojis decoded.\n",
    "\n",
    "    \"\"\"\n",
    "    # Check if the text is a string; if not, return it as is\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    return emoji.demojize(text, delimiters=(\"\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f326ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans the given text by removing HTML tags, decoding HTML entities, removing emojis, and converting to lowercase.\n",
    "\n",
    "    Parameters:\n",
    "    text (str): The text to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "    str: The cleaned text.\n",
    "    \"\"\"\n",
    "    if isinstance(text, str):\n",
    "        # Remove HTML tags\n",
    "        text_clean = re.sub('<.*?>', '', text)\n",
    "        # Decode HTML entities\n",
    "        text_clean = unescape(text_clean)\n",
    "        # Translate emojis\n",
    "        text_clean = translate_emojis(text_clean)\n",
    "        # Convert to lowercase\n",
    "        text_clean = text_clean.lower()\n",
    "        return text_clean\n",
    "    else:\n",
    "        # Return empty string if the input is not a string\n",
    "        return '' if text is None else text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8547a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning HTML Tags\n",
    "def clean_html_tags(text):\n",
    "    \"\"\"\n",
    "    Cleans HTML tags and decodes HTML entities from the given text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned text with HTML tags removed and HTML entities decoded.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        # Return the input as-is if it's not a string\n",
    "        return text\n",
    "    # Remove HTML tags\n",
    "    clean_text = re.sub('<.*?>', '', text)\n",
    "    # Decode HTML entities\n",
    "    clean_text = unescape(clean_text)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2905b0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lenguage Detection Function \n",
    "def detect_language(text):\n",
    "    \"\"\"\n",
    "    Detects the language of the given text.\n",
    "\n",
    "    Parameters:\n",
    "    text (str): The text to detect the language of.\n",
    "\n",
    "    Returns:\n",
    "    str: The detected language of the text, or 'unknown' if the detection fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0c83d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize stemmer and lemmatizer\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text_advanced(text, method=\"lemmatization\", remove_special_chars=True, remove_numbers=True, use_custom_stopwords=False, custom_stopwords=set()):\n",
    "    \"\"\"\n",
    "    Clean the given text using advanced techniques including optional removal of special characters and numbers,\n",
    "    and utilizing custom stopwords.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to be cleaned.\n",
    "        method (str, optional): The cleaning method to be used ('stemming' or 'lemmatization'). Defaults to 'lemmatization'.\n",
    "        remove_special_chars (bool, optional): Whether to remove special characters. Defaults to True.\n",
    "        remove_numbers (bool, optional): Whether to remove numbers. Defaults to True.\n",
    "        use_custom_stopwords (bool, optional): Whether to use custom stopwords. Defaults to False.\n",
    "        custom_stopwords (set, optional): A set of custom stopwords. Defaults to an empty set.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned text.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text  # Return the original value if it's not a string\n",
    "    # Optionally remove special characters and numbers\n",
    "    if remove_special_chars:\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    if remove_numbers:\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "\n",
    "    # Tokenization\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Stopwords\n",
    "    all_stopwords = set(stopwords.words('english'))\n",
    "    if use_custom_stopwords:\n",
    "        all_stopwords = all_stopwords.union(custom_stopwords)\n",
    "\n",
    "    # Stemming or Lemmatization\n",
    "    if method == \"stemming\":\n",
    "        cleaned_words = [stemmer.stem(word) for word in words if word not in all_stopwords]\n",
    "    # Default to lemmatization\n",
    "    else:  \n",
    "        cleaned_words = [lemmatizer.lemmatize(word) for word in words if word not in all_stopwords]\n",
    "\n",
    "    return ' '.join(cleaned_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56671b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying functions to DataFrame\n",
    "df_deduplicated['Body_Emojis'] = df_deduplicated['Body'].apply(extract_emojis)\n",
    "df_deduplicated['Title_Emojis'] = df_deduplicated['Title'].apply(extract_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67c10ce-bdc5-400a-9c32-5fdf3c1e38ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deduplicated['Body_Noemojis'] = df_deduplicated['Body'].apply(translate_emojis)\n",
    "df_deduplicated['Title_Noemojis'] = df_deduplicated['Title'].apply(translate_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d02ec95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deduplicated['Body_Clean_Basics'] = df_deduplicated['Body'].apply(clean_text)\n",
    "df_deduplicated['Title_Clean_Basics'] = df_deduplicated['Title'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b711702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deduplicated['Body_HTML'] = df_deduplicated['Body'].apply(clean_html_tags)\n",
    "df_deduplicated['Title_HTML'] = df_deduplicated['Title'].apply(clean_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9d7851-6726-46ec-a887-caee1c2039bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_deduplicated['language'] = df_deduplicated['Body_HTML'].apply(detect_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3063099e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deduplicated['Body_Clean'] = df_deduplicated['Body_Clean_Basics'].apply(lambda x: clean_text_advanced(x, \n",
    "                                                                                                         method=\"lemmatization\",\n",
    "                                                                                                         remove_special_chars=False, \n",
    "                                                                                                         remove_numbers=False, \n",
    "                                                                                                         use_custom_stopwords=False, \n",
    "                                                                                                         custom_stopwords=set()))\n",
    "df_deduplicated['Title_Clean'] = df_deduplicated['Title_Clean_Basics'].apply(lambda x: clean_text_advanced(x, \n",
    "                                                                                                         method=\"lemmatization\",\n",
    "                                                                                                         remove_special_chars=False, \n",
    "                                                                                                         remove_numbers=False, \n",
    "                                                                                                         use_custom_stopwords=False, \n",
    "                                                                                                         custom_stopwords=set()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c6e62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deduplicated['Clean_Text'] = df_deduplicated['Title_Clean'].astype(str) + '\\n\\n' + df_deduplicated['Body_Clean'].astype(str)\n",
    "df_deduplicated['Clean_Text_Basic'] = df_deduplicated['Title_Clean_Basics'].astype(str) + '\\n\\n' + df_deduplicated['Body_Clean_Basics'].astype(str)\n",
    "df_deduplicated['All_Emojis'] = df_deduplicated['Title_Emojis'].astype(str) + '\\n\\n' + df_deduplicated['Body_Emojis'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829d69a0",
   "metadata": {},
   "source": [
    "## Classifier Modeling (Classic ML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b59381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example placeholder for keyword matching\n",
    "keywords = ['two girls special', 'two girl special','duo special', '2 girls', 'double trouble', 'double the fun'] #Pretty conservative list of keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cca9b7-4181-4f8f-b6ba-909cd24a2ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_keywords(text):\n",
    "    for keyword in keywords:\n",
    "        if keyword in text:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "df_deduplicated['Weak_Label'] = df_deduplicated['Clean_Text_Basic'].apply(check_keywords)\n",
    "df_deduplicated['Weak_Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b79114",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deduplicated['Label'] = df_deduplicated.apply(lambda row: 1 if row['Multiple People or Not'] == 'Yes' and row['Massage Parlor/Asian Agency or Not'] == 'No' else 0, axis=1)\n",
    "df_deduplicated['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624e6bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "output_csv_path = 'Fine_Tune_Data.csv'\n",
    "df_deduplicated.to_csv(output_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed18254f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_deduplicated['Clean_Text'], df_deduplicated['Label'],test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa1a2cc",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd5a483",
   "metadata": {},
   "source": [
    "#### Bag of Words (BoW) Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50144a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing the text data\n",
    "vectorizer = CountVectorizer() #Bag of Words\n",
    "X_train_counts = vectorizer.fit_transform(X_train)\n",
    "X_test_counts = vectorizer.transform(X_test)\n",
    "\n",
    "# Training a Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_counts, y_train)\n",
    "\n",
    "# Making predictions and evaluating the model\n",
    "y_pred = clf.predict(X_test_counts)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5edd74",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ee8a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming count matrix to a normalized tf-idf representation\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "# Re-training the classifier with TF-IDF features\n",
    "clf_tfidf = MultinomialNB()\n",
    "clf_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Making predictions and evaluating the model\n",
    "y_pred_tfidf = clf_tfidf.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d4a336",
   "metadata": {},
   "source": [
    "#### N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e63dce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing the text data with unigrams, bigrams, and trigrams using TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 3), stop_words='english')\n",
    "X_train_tfidf_gram = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf_gram = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Training the Naive Bayes classifier with the enhanced TF-IDF features\n",
    "clf_tfidf_gram = MultinomialNB()\n",
    "clf_tfidf_gram.fit(X_train_tfidf_gram, y_train)\n",
    "\n",
    "# Making predictions and evaluating the model\n",
    "y_pred_tfidf_gram = clf_tfidf_gram.predict(X_test_tfidf_gram)\n",
    "print(classification_report(y_test, y_pred_tfidf_gram))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af259379",
   "metadata": {},
   "source": [
    "#### Savings Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cbca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = \"Models\"  # Folder in your repository where you want to save models\n",
    "\n",
    "# Function to save the model\n",
    "def save_model(model, model_name, models_directory=models_dir):\n",
    "    if not os.path.isdir(models_directory):\n",
    "        os.makedirs(models_directory)  # Create the Models directory if it doesn't exist\n",
    "    dump(model, f\"{models_directory}/{model_name}.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f4125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models after training\n",
    "save_model(clf, 'naive_bayes_bow')\n",
    "save_model(clf_tfidf, 'naive_bayes_tfidf')\n",
    "save_model(clf_tfidf_gram, 'naive_bayes_tfidf_gram')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9514f4",
   "metadata": {},
   "source": [
    "### Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8276a7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "# Vectorization and Model Pipeline using imblearn's pipeline\n",
    "pipeline = make_pipeline_imblearn(\n",
    "    TfidfVectorizer(ngram_range=(1, 3)),\n",
    "    SMOTE(random_state=42),\n",
    "    MultinomialNB()\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# If you want to save the pipeline model\n",
    "save_model(pipeline, 'smote_naive_bayes_tfidf')\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred, target_names=['Class 0', 'Class 1']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3282155",
   "metadata": {},
   "source": [
    "### Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f00f0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_deduplicated['Clean_Text'], df_deduplicated['Label'], test_size=0.3, random_state=42)\n",
    "\n",
    "# Define vectorization methods\n",
    "vectorization_methods = {\n",
    "    'BoW': CountVectorizer(),\n",
    "    'TF-IDF': TfidfVectorizer(),\n",
    "    'N-Grams': TfidfVectorizer(ngram_range=(1, 3))\n",
    "}\n",
    "\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Support Vector Machine\": SVC(),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss')  # For XGBoost, avoid warnings\n",
    "}\n",
    "# Initialize an empty DataFrame to store results\n",
    "results_balanced = pd.DataFrame(columns=[\"Feature Engineering\", \"Classifier\", \"Overall Accuracy\", \"Class 1 Precision\", \"Class 1 Recall\", \"Class 1 F1-Score\"])\n",
    "\n",
    "# Loop through each vectorization method\n",
    "for vec_name, vectorizer in vectorization_methods.items():\n",
    "    # Apply vectorization\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "    \n",
    "    # Balancing the dataset using SMOTE\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_vec_smote, y_train_smote = smote.fit_resample(X_train_vec, y_train)\n",
    "    \n",
    "    # Loop through classifiers to train and evaluate\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        # Train the model using the balanced dataset\n",
    "        clf.fit(X_train_vec_smote, y_train_smote)\n",
    "        \n",
    "        # Predict on the test set\n",
    "        y_pred = clf.predict(X_test_vec)\n",
    "\n",
    "        save_model(clf, f\"{clf_name}_{vec_name}\")\n",
    "        \n",
    "        # Calculate overall accuracy and metrics for class 1\n",
    "        overall_accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # Calculate precision, recall, f1-score specifically for class 1\n",
    "        precision, recall, f1, _ = score(y_test, y_pred, labels=[1], average='binary')\n",
    "        \n",
    "        # Create a temporary DataFrame for the current iteration's results\n",
    "        temp_df = pd.DataFrame({\n",
    "            \"Feature Engineering\": [vec_name],\n",
    "            \"Classifier\": [clf_name],\n",
    "            \"Overall Accuracy\": [overall_accuracy],\n",
    "            \"Class 1 Precision\": [precision],\n",
    "            \"Class 1 Recall\": [recall],\n",
    "            \"Class 1 F1-Score\": [f1]\n",
    "        })\n",
    "        \n",
    "        # Concatenate with the main results DataFrame\n",
    "        results_balanced = pd.concat([results_balanced, temp_df], ignore_index=True)\n",
    "\n",
    "# Sort results by Class 1 F1-Score for comparison\n",
    "results_balanced.sort_values(by=\"Class 1 F1-Score\", ascending=False, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc92710",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c076bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame to store results\n",
    "results = pd.DataFrame(columns=[\"Feature Engineering\", \"Classifier\", \"Overall Accuracy\", \"Class 1 Precision\", \"Class 1 Recall\", \"Class 1 F1-Score\"])\n",
    "\n",
    "# Loop through each vectorization method\n",
    "for vec_name, vectorizer in vectorization_methods.items():\n",
    "    # Apply vectorization\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "    \n",
    "    # Loop through classifiers to train and evaluate\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        # Train the model using the original dataset\n",
    "        clf.fit(X_train_vec, y_train)\n",
    "        \n",
    "        # Predict on the test set\n",
    "        y_pred = clf.predict(X_test_vec)\n",
    "        \n",
    "        # Calculate overall accuracy and metrics for class 1\n",
    "        overall_accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # Calculate precision, recall, f1-score specifically for class 1\n",
    "        precision, recall, f1, _ = score(y_test, y_pred, labels=[1], average='binary')\n",
    "        \n",
    "        # Create a temporary DataFrame for the current iteration's results\n",
    "        temp_df = pd.DataFrame({\n",
    "            \"Feature Engineering\": [vec_name],\n",
    "            \"Classifier\": [clf_name],\n",
    "            \"Overall Accuracy\": [overall_accuracy],\n",
    "            \"Class 1 Precision\": [precision],\n",
    "            \"Class 1 Recall\": [recall],\n",
    "            \"Class 1 F1-Score\": [f1]\n",
    "        })\n",
    "        \n",
    "        # Concatenate with the main results DataFrame\n",
    "        results = pd.concat([results, temp_df], ignore_index=True)\n",
    "\n",
    "# Sort results by Class 1 F1-Score for comparison\n",
    "results.sort_values(by=\"Class 1 F1-Score\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e385086",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a81288",
   "metadata": {},
   "source": [
    "#### Embeddings Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4df194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory for models and embeddings\n",
    "models_embeddings_dir = 'Models_Embeddings'\n",
    "os.makedirs(models_embeddings_dir, exist_ok=True)\n",
    "\n",
    "def save_model_embeddings(model, model_name, method, is_embedding=False):\n",
    "    filename = os.path.join(models_embeddings_dir, model_name)\n",
    "    if is_embedding:\n",
    "        if method in ['Word2Vec', 'FastText', 'GloVe']:\n",
    "            model.save(f'{filename}.model')\n",
    "        elif method in ['BERT', 'USE']:\n",
    "        # For SentenceTransformer or TensorFlow Hub models, saving with joblib or similar is not straightforward\n",
    "        # Consider saving configurations or necessary info to recreate the model instead\n",
    "            print(f\"Model type '{method}' cannot be directly saved with joblib. Consider manually saving model components.\")\n",
    "    else:\n",
    "        dump(model, f'{filename}.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29310fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to generate embeddings\n",
    "def generate_embeddings(method, texts):\n",
    "    if method == 'Word2Vec':\n",
    "        model = Word2Vec(sentences=[text.split() for text in texts], vector_size=100, window=5, min_count=1, workers=4)\n",
    "        embeddings = np.array([np.mean([model.wv[word] for word in text.split() if word in model.wv] or [np.zeros(100)], axis=0) for text in texts])\n",
    "    elif method == 'FastText':\n",
    "        model = FastText(sentences=[text.split() for text in texts], vector_size=100, window=5, min_count=1, workers=4)\n",
    "        embeddings = np.array([np.mean([model.wv[word] for word in text.split() if word in model.wv] or [np.zeros(100)], axis=0) for text in texts])\n",
    "    elif method == 'GloVe':\n",
    "        glove_input_file = 'glove.6B.100d.txt'  # Specify the correct path to the GloVe file\n",
    "        word2vec_output_file = 'glove.6B.100d.txt.word2vec'\n",
    "        glove2word2vec(glove_input_file, word2vec_output_file)\n",
    "        model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)\n",
    "        embeddings = np.array([np.mean([model[word] for word in text.split() if word in model] or [np.zeros(100)], axis=0) for text in texts])\n",
    "    elif method == 'BERT':\n",
    "        model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "        embeddings = model.encode(texts)\n",
    "    elif method == 'USE':\n",
    "        model = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "        embeddings = np.array(model(texts))\n",
    "    \n",
    "    # Save the model or embeddings\n",
    "    save_model_embeddings(model, f'{method}_model', method, is_embedding=True)\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a31c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_embeddings = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Support Vector Machine\": SVC(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss')  # For XGBoost, avoid warnings\n",
    "}\n",
    "\n",
    "# Results DataFrame\n",
    "results_embeddings = pd.DataFrame()\n",
    "\n",
    "# Assuming 'Clean_Text' and 'Label' are columns in your DataFrame\n",
    "texts = df_deduplicated['Clean_Text'].tolist()\n",
    "labels = df_deduplicated['Label'].tolist()\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Loop over embedding methods\n",
    "for method in ['Word2Vec', 'FastText', 'GloVe', 'BERT', 'USE']:\n",
    "    # Generate embeddings\n",
    "    X_train_embed = generate_embeddings(method, X_train)\n",
    "    X_test_embed = generate_embeddings(method, X_test)\n",
    "    \n",
    "    # Apply SMOTE\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_vec_smote, y_train_smote = smote.fit_resample(np.array(X_train_embed), y_train)\n",
    "\n",
    "    for clf_name, clf in classifiers_embeddings.items():\n",
    "        clf.fit(X_train_vec_smote, y_train_smote)\n",
    "        y_pred = clf.predict(np.array(X_test_embed))\n",
    "\n",
    "        # Calculate metrics\n",
    "        overall_accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision, recall, f1, _ = score(y_test, y_pred, labels=[1], average='binary')\n",
    "\n",
    "        # Temporary DataFrame for the current iteration's results\n",
    "        temp_df = pd.DataFrame({\n",
    "            \"Embedding\": [method],\n",
    "            \n",
    "            \"Classifier\": [clf_name],\n",
    "            \"Overall Accuracy\": [overall_accuracy],\n",
    "            \"Class 1 Precision\": [precision],\n",
    "            \"Class 1 Recall\": [recall],\n",
    "            \"Class 1 F1-Score\": [f1]\n",
    "        })\n",
    "\n",
    "        # Concatenate with the main results DataFrame\n",
    "        results_embeddings = pd.concat([results_embeddings, temp_df], ignore_index=True)\n",
    "\n",
    "        # Save the trained classifier\n",
    "        save_model(clf, f'{method}_{clf_name}_classifier', models_directory = 'Model_Embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c160fea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sorted results\n",
    "results_embeddings.sort_values(by=\"Class 1 F1-Score\", ascending=False, inplace=True)\n",
    "display(results_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c6514b",
   "metadata": {},
   "source": [
    "#### Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f4fa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(df):\n",
    "    # Define the metrics you want to plot\n",
    "    #metrics = ['Overall Accuracy', 'Class 1 Precision', 'Class 1 Recall', 'Class 1 F1-Score']\n",
    "    metrics = ['Class 1 Recall', 'Class 1 F1-Score']\n",
    "    \n",
    "    for metric in metrics:\n",
    "        fig = px.bar(df, x='Embedding', y=metric, color='Classifier', barmode='group',\n",
    "                     title=f'{metric} by Embedding and Classifier',\n",
    "                     category_orders={\"Embedding\": [\"Word2Vec\", \"GloVe\", \"BERT\", \"USE\", \"FastText\"]})\n",
    "        fig.update_layout(xaxis_title=\"Embedding\",\n",
    "                          yaxis_title=metric,\n",
    "                          legend_title=\"Classifier\")\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d85f601",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.rename(columns={'Feature Engineering': 'Embedding'}, inplace=True)\n",
    "results_balanced.rename(columns={'Feature Engineering': 'Embedding'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67632f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column to each DataFrame to indicate the type of run\n",
    "results['Run Type'] = 'Without SMOTE'\n",
    "results_balanced['Run Type'] = 'With SMOTE'\n",
    "results_embeddings['Run Type'] = 'Advanced Embeddings with SMOTE'\n",
    "\n",
    "# Concatenate all three DataFrames\n",
    "combined_df = pd.concat([results, results_balanced, results_embeddings])\n",
    "\n",
    "# Create a unique identifier for each Embedding and Classifier combination\n",
    "combined_df['Combination'] = combined_df['Embedding'] + ' + ' + combined_df['Classifier']\n",
    "\n",
    "melted_df = combined_df.melt(id_vars=['Embedding', 'Classifier', 'Run Type'], \n",
    "                             value_vars=['Overall Accuracy', 'Class 1 Precision', 'Class 1 Recall', 'Class 1 F1-Score'],\n",
    "                             var_name='Metric', value_name='Performance Value')\n",
    "\n",
    "# Create a unique identifier for each Embedding and Classifier combination\n",
    "melted_df['Combination'] = melted_df['Embedding'] + ' + ' + melted_df['Classifier'] + ' (' + melted_df['Run Type'] + ')'\n",
    "\n",
    "# Define the desired metric order\n",
    "metric_order = ['Overall Accuracy', 'Class 1 Precision', 'Class 1 Recall', 'Class 1 F1-Score']\n",
    "\n",
    "# Ensure 'Metric' column is ordered correctly\n",
    "melted_df['Metric'] = pd.Categorical(melted_df['Metric'], categories=metric_order, ordered=True)\n",
    "\n",
    "# Sort melted_df by 'Class 1 Recall' to identify top 6 models\n",
    "top_recall_combinations = melted_df[melted_df['Metric'] == 'Class 1 Recall']\\\n",
    "    .sort_values(by='Performance Value', ascending=False)\\\n",
    "    .head(6)['Combination'].unique()\n",
    "\n",
    "# Define a list of unique colors for the top 6 lines\n",
    "top_colors = ['#E63946', '#F4A261', '#2A9D8F', '#264653', '#E9C46A', '#F4E76E']\n",
    "\n",
    "# Initialize an empty figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces for the top 6 models with unique colors\n",
    "for i, combination in enumerate(top_recall_combinations):\n",
    "    df_filtered = melted_df[melted_df['Combination'] == combination]\n",
    "    fig.add_trace(go.Scatter(x=df_filtered['Metric'], y=df_filtered['Performance Value'],\n",
    "                             name=combination, mode='lines',\n",
    "                             line=dict(color=top_colors[i], width=3)))  # Use unique color and slightly thicker lines\n",
    "\n",
    "# Then, add traces for the rest of the models in dark gray\n",
    "for combination in melted_df['Combination'].unique():\n",
    "    if combination not in top_recall_combinations:\n",
    "        df_filtered = melted_df[melted_df['Combination'] == combination]\n",
    "        fig.add_trace(go.Scatter(x=df_filtered['Metric'], y=df_filtered['Performance Value'],\n",
    "                                 name=combination, mode='lines',\n",
    "                                 line=dict(color='darkgray', width=2)))  # Standard lines in dark gray\n",
    "\n",
    "# Customize layout\n",
    "fig.update_layout({\n",
    "    'plot_bgcolor': 'rgba(0, 0, 0, 0)',\n",
    "    'paper_bgcolor': 'rgba(0, 0, 0, 0)',\n",
    "    'title': {\n",
    "        'text': \"<b>Performance Across Different Metrics and Runs</b>\",\n",
    "        'y': 0.9,\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top',\n",
    "        'font': {'size': 24, 'family': \"Arial\", 'color': \"black\"}\n",
    "    },\n",
    "    'xaxis_title': '<b>Metric</b>',\n",
    "    'yaxis_title': '<b>Performance Value</b>',\n",
    "    'xaxis': {'categoryorder': 'array', 'categoryarray': metric_order},\n",
    "    'xaxis_title_font': {'size': 18, 'family': \"Arial\"},\n",
    "    'yaxis_title_font': {'size': 18, 'family': \"Arial\"},\n",
    "    'legend_title': '<b>Embedding + Classifier + Run Type</b>',\n",
    "    'height': 600\n",
    "})\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b672af",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2c4079",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f45e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Step 1: Split the data into training and testing sets\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(df_deduplicated['Clean_Text'], df_deduplicated['Label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Vectorization - Apply TF-IDF to the training and testing data separately\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_raw)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test_raw)\n",
    "\n",
    "# Step 3: Define the parameter grid for MultinomialNB\n",
    "param_grid_nb = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Step 4: Initialize the GridSearchCV object\n",
    "grid_search_nb = GridSearchCV(MultinomialNB(), param_grid_nb, cv=5, scoring='recall')\n",
    "\n",
    "# Step 5: Fit GridSearchCV to the training data\n",
    "grid_search_nb.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best parameters for maximizing recall:\", grid_search_nb.best_params_)\n",
    "print(\"Best recall score:\", grid_search_nb.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e9c9a3",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dcc011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for LogisticRegression\n",
    "param_grid_lr = {'C': [0.01, 0.1, 1, 10, 100], 'solver': ['liblinear', 'lbfgs']}\n",
    "\n",
    "# Initialize the GridSearchCV object\n",
    "grid_search_lr = GridSearchCV(LogisticRegression(max_iter=1000), param_grid_lr, cv=5, scoring='recall')\n",
    "\n",
    "# Fit it to the data\n",
    "grid_search_lr.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best parameters for Logistic Regression:\", grid_search_lr.best_params_)\n",
    "print(\"Best recall score:\", grid_search_lr.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45e02f1",
   "metadata": {},
   "source": [
    "### Model Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97d4d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import recall_score, make_scorer\n",
    "\n",
    "# Pipelines for each classifier\n",
    "pipeline_nb = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('nb', MultinomialNB(alpha=grid_search_nb.best_params_['alpha']))\n",
    "])\n",
    "\n",
    "pipeline_lr = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('lr', LogisticRegression(C=grid_search_lr.best_params_['C'], solver=grid_search_lr.best_params_['solver'], max_iter=1000))\n",
    "])\n",
    "\n",
    "# Voting classifier with pipelines\n",
    "voting_clf_pipeline = VotingClassifier(estimators=[\n",
    "    ('nb', pipeline_nb), \n",
    "    ('lr', pipeline_lr)\n",
    "], voting='soft')\n",
    "\n",
    "# Fit the voting classifier on raw text data\n",
    "voting_clf_pipeline.fit(X_train_raw, y_train)\n",
    "\n",
    "# Evaluate the voting classifier\n",
    "accuracy = voting_clf_pipeline.score(X_test_raw, y_test)\n",
    "print(f'Voting Classifier Accuracy: {accuracy}')\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = voting_clf_pipeline.predict(X_test_raw)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, y_pred, average='binary')  # adjust the average parameter as per your use case\n",
    "print(f'Recall Score: {recall}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d09f875",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004b9e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, Conv1D, MaxPooling1D, LSTM, Bidirectional, Input, Reshape\n",
    "# Assuming df_deduplicated['Clean_Text'] and df_deduplicated['Label'] are your data and labels\n",
    "\n",
    "# Step 1: Split the data into training, validation, and testing sets\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(df_deduplicated['Clean_Text'], df_deduplicated['Label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Tokenizer\n",
    "tokenizer = Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(X_train_raw)\n",
    "\n",
    "# Convert text sequences into integer sequences\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train_raw)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test_raw)\n",
    "\n",
    "# Pad sequences to ensure uniform length\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=100)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=100)\n",
    "\n",
    "# Apply SMOTE for class imbalance\n",
    "smote = SMOTE()\n",
    "X_train_pad_resampled, y_train_resampled = smote.fit_resample(X_train_pad, y_train)\n",
    "\n",
    "\n",
    "# Define CNN model\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Embedding(input_dim=20000, output_dim=100, input_length=100))\n",
    "cnn_model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "cnn_model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "cnn_model.add(GlobalAveragePooling1D())\n",
    "cnn_model.add(Dense(1, activation='sigmoid'))\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define the model architecture\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(input_dim=20000, output_dim=100, input_length=100))\n",
    "lstm_model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "lstm_model.add(Bidirectional(LSTM(32)))\n",
    "lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define the original model\n",
    "original_model = Sequential()\n",
    "original_model.add(Embedding(input_dim=20000, output_dim=100, input_length=100))\n",
    "original_model.add(GlobalAveragePooling1D())\n",
    "original_model.add(Dense(1, activation='sigmoid'))\n",
    "original_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c99cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate models\n",
    "cnn_model.fit(X_train_pad_resampled, y_train_resampled, epochs=10, batch_size=32, validation_data=(X_test_pad, y_test))\n",
    "lstm_model.fit(X_train_pad_resampled, y_train_resampled, epochs=10, batch_size=32, validation_data=(X_test_pad, y_test))\n",
    "original_model.fit(X_train_pad_resampled, y_train_resampled, epochs=10, batch_size=32, validation_data=(X_test_pad, y_test))\n",
    "\n",
    "# Evaluate models on test set\n",
    "cnn_test_loss, cnn_test_acc = cnn_model.evaluate(X_test_pad, y_test, verbose=0)\n",
    "lstm_test_loss, lstm_test_acc = lstm_model.evaluate(X_test_pad, y_test, verbose=0)\n",
    "original_test_loss, original_test_acc = original_model.evaluate(X_test_pad, y_test, verbose=0)\n",
    "\n",
    "print(f'CNN Test Accuracy: {cnn_test_acc}')\n",
    "print(f'LSTM Test Accuracy: {lstm_test_acc}')\n",
    "print(f'Original Model Test Accuracy: {original_test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff6aee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to generate Word2Vec embeddings\n",
    "def generate_word2vec_embeddings(texts):\n",
    "    model = Word2Vec(sentences=[text.split() for text in texts], vector_size=100, window=5, min_count=1, workers=4)\n",
    "    embeddings = np.array([np.mean([model.wv[word] for word in text.split() if word in model.wv] or [np.zeros(100)], axis=0) for text in texts])\n",
    "    return embeddings\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Perform stratified train-test split\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_index, test_index = next(sss.split(df_deduplicated['Clean_Text'], df_deduplicated['Label']))\n",
    "X_train_raw, X_test_raw = df_deduplicated['Clean_Text'].iloc[train_index], df_deduplicated['Clean_Text'].iloc[test_index]\n",
    "y_train, y_test = df_deduplicated['Label'].iloc[train_index], df_deduplicated['Label'].iloc[test_index]\n",
    "\n",
    "# Generate Word2Vec embeddings for training and test data\n",
    "X_train_embed = generate_word2vec_embeddings(X_train_raw)\n",
    "X_test_embed = generate_word2vec_embeddings(X_test_raw)\n",
    "\n",
    "# Apply SMOTE for class imbalance\n",
    "smote = SMOTE()\n",
    "X_train_embed_resampled, y_train_resampled = smote.fit_resample(X_train_embed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ce1a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define CNN model with embeddings\n",
    "# cnn_embed_model = Sequential()\n",
    "# cnn_embed_model.add(Input(shape=(X_train_embed.shape[1],)))  # Input shape based on embeddings\n",
    "# cnn_embed_model.add(Reshape((X_train_embed.shape[1], 1)))  # Reshape input to 3D\n",
    "# cnn_embed_model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "# cnn_embed_model.add(MaxPooling1D(pool_size=2))\n",
    "# cnn_embed_model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "# cnn_embed_model.add(MaxPooling1D(pool_size=2))\n",
    "# cnn_embed_model.add(GlobalAveragePooling1D())\n",
    "# cnn_embed_model.add(Dense(1, activation='sigmoid'))\n",
    "# cnn_embed_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Define LSTM model with embeddings\n",
    "# lstm_embed_model = Sequential()\n",
    "# lstm_embed_model.add(Input(shape=(X_train_embed.shape[1],)))  # Input shape based on embeddings\n",
    "# lstm_embed_model.add(Reshape((X_train_embed.shape[1], 1)))  # Reshape input to 3D\n",
    "# lstm_embed_model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "# lstm_embed_model.add(Bidirectional(LSTM(32)))\n",
    "# lstm_embed_model.add(Dense(1, activation='sigmoid'))\n",
    "# lstm_embed_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Define the original model with embeddings\n",
    "# original_embed_model = Sequential()\n",
    "# original_embed_model.add(Input(shape=(X_train_embed.shape[1],)))  # Input shape based on embeddings\n",
    "# original_embed_model.add(Dense(64, activation='relu'))\n",
    "# original_embed_model.add(Dense(1, activation='sigmoid'))\n",
    "# original_embed_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Define autoencoder model with embeddings\n",
    "# autoencoder_model = Sequential()\n",
    "# autoencoder_model.add(Input(shape=(X_train_embed.shape[1],)))  # Input shape based on embeddings\n",
    "# autoencoder_model.add(Dense(64, activation='relu'))  # Encoder layer\n",
    "# autoencoder_model.add(Dense(X_train_embed.shape[1], activation='sigmoid'))  # Decoder layer\n",
    "# autoencoder_model.add(Dense(1, activation='sigmoid'))  # Classification layer\n",
    "# autoencoder_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fadb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "cnn_embed_model = Sequential()\n",
    "cnn_embed_model.add(Input(shape=(X_train_embed.shape[1],)))\n",
    "cnn_embed_model.add(Reshape((X_train_embed.shape[1], 1)))\n",
    "cnn_embed_model.add(Conv1D(filters=128, kernel_size=5, activation='relu', kernel_regularizer='l2'))\n",
    "cnn_embed_model.add(MaxPooling1D(pool_size=2))\n",
    "cnn_embed_model.add(Conv1D(filters=64, kernel_size=3, activation='relu', kernel_regularizer='l2'))\n",
    "cnn_embed_model.add(MaxPooling1D(pool_size=2))\n",
    "cnn_embed_model.add(Conv1D(filters=32, kernel_size=3, activation='relu', kernel_regularizer='l2'))\n",
    "cnn_embed_model.add(GlobalAveragePooling1D())\n",
    "cnn_embed_model.add(Dense(64, activation='relu', kernel_regularizer='l2'))\n",
    "cnn_embed_model.add(Dense(1, activation='sigmoid'))\n",
    "cnn_embed_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "cnn_embed_model.fit(X_train_embed_resampled, y_train_resampled, epochs=50, batch_size=32, validation_data=(X_test_embed, y_test), callbacks=[early_stopping])\n",
    "\n",
    "lstm_embed_model = Sequential()\n",
    "lstm_embed_model.add(Input(shape=(X_train_embed.shape[1],)))\n",
    "lstm_embed_model.add(Reshape((X_train_embed.shape[1], 1)))\n",
    "lstm_embed_model.add(Bidirectional(LSTM(64, return_sequences=True, kernel_regularizer='l2', recurrent_regularizer='l2')))\n",
    "lstm_embed_model.add(Bidirectional(LSTM(32, return_sequences=True, kernel_regularizer='l2', recurrent_regularizer='l2')))\n",
    "lstm_embed_model.add(Bidirectional(LSTM(16, kernel_regularizer='l2', recurrent_regularizer='l2')))\n",
    "lstm_embed_model.add(Dense(64, activation='relu', kernel_regularizer='l2'))\n",
    "lstm_embed_model.add(Dense(1, activation='sigmoid'))\n",
    "lstm_embed_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "lstm_embed_model.fit(X_train_embed_resampled, y_train_resampled, epochs=50, batch_size=32, validation_data=(X_test_embed, y_test), callbacks=[early_stopping])\n",
    "\n",
    "original_embed_model = Sequential()\n",
    "original_embed_model.add(Input(shape=(X_train_embed.shape[1],)))\n",
    "original_embed_model.add(Dense(128, activation='relu', kernel_regularizer='l2'))\n",
    "original_embed_model.add(Dense(64, activation='relu', kernel_regularizer='l2'))\n",
    "original_embed_model.add(Dense(32, activation='relu', kernel_regularizer='l2'))\n",
    "original_embed_model.add(Dense(1, activation='sigmoid'))\n",
    "original_embed_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "original_embed_model.fit(X_train_embed_resampled, y_train_resampled, epochs=50, batch_size=32, validation_data=(X_test_embed, y_test), callbacks=[early_stopping])\n",
    "\n",
    "autoencoder_model = Sequential()\n",
    "autoencoder_model.add(Input(shape=(X_train_embed.shape[1],)))\n",
    "autoencoder_model.add(Dense(128, activation='relu', kernel_regularizer='l2'))  # Encoder layer\n",
    "autoencoder_model.add(Dense(64, activation='relu', kernel_regularizer='l2'))  # Encoder layer\n",
    "autoencoder_model.add(Dense(32, activation='relu', kernel_regularizer='l2'))  # Bottleneck layer\n",
    "autoencoder_model.add(Dense(64, activation='relu', kernel_regularizer='l2'))  # Decoder layer\n",
    "autoencoder_model.add(Dense(128, activation='relu', kernel_regularizer='l2'))  # Decoder layer\n",
    "autoencoder_model.add(Dense(X_train_embed.shape[1], activation='sigmoid'))  # Output layer\n",
    "autoencoder_model.add(Dense(64, activation='relu', kernel_regularizer='l2'))  # Classification layer\n",
    "autoencoder_model.add(Dense(1, activation='sigmoid'))  # Classification output\n",
    "autoencoder_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "autoencoder_model.fit(X_train_embed_resampled, y_train_resampled, epochs=50, batch_size=32, validation_data=(X_test_embed, y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dc8a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models on test set\n",
    "cnn_embed_test_loss, cnn_embed_test_acc = cnn_embed_model.evaluate(X_test_embed, y_test, verbose=0)\n",
    "lstm_embed_test_loss, lstm_embed_test_acc = lstm_embed_model.evaluate(X_test_embed, y_test, verbose=0)\n",
    "autoencoder_embed_test_loss, autoencoder_embed_test_acc = autoencoder_model.evaluate(X_test_embed, y_test, verbose=0)\n",
    "original_embed_test_loss, original_embed_test_acc = original_embed_model.evaluate(X_test_embed, y_test, verbose=0)\n",
    "\n",
    "print(f'CNN with Word2Vec Embeddings Test Accuracy: {cnn_embed_test_acc}')\n",
    "print(f'LSTM with Word2Vec Embeddings Test Accuracy: {lstm_embed_test_acc}')\n",
    "print(f'Autoencoder Model with Word2Vec Embeddings Test Accuracy: {autoencoder_embed_test_acc}')\n",
    "print(f'Original Model with Word2Vec Embeddings Test Accuracy: {original_embed_test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc76a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the threshold for class 1\n",
    "threshold = 0.2\n",
    "\n",
    "# Evaluate models on test set\n",
    "cnn_embed_pred = (cnn_embed_model.predict(X_test_embed) > threshold).astype(int)\n",
    "print(\"CNN with Word2Vec Embeddings Classification Report:\")\n",
    "print(classification_report(y_test, cnn_embed_pred))\n",
    "\n",
    "lstm_embed_pred = (lstm_embed_model.predict(X_test_embed) > threshold).astype(int)\n",
    "print(\"LSTM with Word2Vec Embeddings Classification Report:\")\n",
    "print(classification_report(y_test, lstm_embed_pred))\n",
    "\n",
    "autoencoder_pred = (autoencoder_model.predict(X_test_embed) > threshold).astype(int)\n",
    "print(\"Autoencoder with Word2Vec Embeddings Classification Report:\")\n",
    "print(classification_report(y_test, autoencoder_pred))\n",
    "\n",
    "original_embed_pred = (original_embed_model.predict(X_test_embed) > threshold).astype(int)\n",
    "print(\"Original Model with Word2Vec Embeddings Classification Report:\")\n",
    "print(classification_report(y_test, original_embed_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665c7d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load the pre-trained models\n",
    "sbert_model = SentenceTransformer('stsb-mpnet-base-v2')\n",
    "simcse_sup_model = SentenceTransformer('princeton-nlp/sup-simcse-roberta-large')\n",
    "simcse_unsup_model = SentenceTransformer('princeton-nlp/unsup-simcse-roberta-large')\n",
    "\n",
    "# Generate embeddings for training and test data\n",
    "X_train_sbert = sbert_model.encode(X_train_raw.tolist(), show_progress_bar=True)\n",
    "X_test_sbert = sbert_model.encode(X_test_raw.tolist(), show_progress_bar=True)\n",
    "\n",
    "X_train_simcse_sup = simcse_sup_model.encode(X_train_raw.tolist(), show_progress_bar=True)\n",
    "X_test_simcse_sup = simcse_sup_model.encode(X_test_raw.tolist(), show_progress_bar=True)\n",
    "\n",
    "X_train_simcse_unsup = simcse_unsup_model.encode(X_train_raw.tolist(), show_progress_bar=True)\n",
    "X_test_simcse_unsup = simcse_unsup_model.encode(X_test_raw.tolist(), show_progress_bar=True)\n",
    "\n",
    "# Apply SMOTE for class imbalance\n",
    "smote = SMOTE()\n",
    "X_train_sbert_resampled, y_train_resampled = smote.fit_resample(X_train_sbert, y_train)\n",
    "X_train_simcse_sup_resampled, _ = smote.fit_resample(X_train_simcse_sup, y_train)\n",
    "X_train_simcse_unsup_resampled, _ = smote.fit_resample(X_train_simcse_unsup, y_train)\n",
    "\n",
    "# Train and evaluate models\n",
    "models = {\n",
    "    'SBERT': LogisticRegression(),\n",
    "    'SimCSE Supervised': LogisticRegression(),\n",
    "    'SimCSE Unsupervised': LogisticRegression()\n",
    "}\n",
    "\n",
    "embeddings = {\n",
    "    'SBERT': (X_train_sbert_resampled, X_test_sbert),\n",
    "    'SimCSE Supervised': (X_train_simcse_sup_resampled, X_test_simcse_sup),\n",
    "    'SimCSE Unsupervised': (X_train_simcse_unsup_resampled, X_test_simcse_unsup)\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    X_train_emb, X_test_emb = embeddings[model_name]\n",
    "    model.fit(X_train_emb, y_train_resampled)\n",
    "    y_pred = model.predict(X_test_emb)\n",
    "    print(f\"{model_name} Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f603b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation Functions\n",
    "def back_translation(texts, src_lang='en', tgt_lang='fr'):\n",
    "    from googletrans import Translator\n",
    "    translator = Translator()\n",
    "    augmented_texts = []\n",
    "    for text in texts:\n",
    "        translation = translator.translate(text, src=src_lang, dest=tgt_lang)\n",
    "        back_translation = translator.translate(translation.text, src=tgt_lang, dest=src_lang)\n",
    "        augmented_texts.append(back_translation.text)\n",
    "    return augmented_texts\n",
    "\n",
    "def synonym_replacement(texts, n=1):\n",
    "    import nltk\n",
    "    from nltk.corpus import wordnet\n",
    "    augmented_texts = []\n",
    "    for text in texts:\n",
    "        words = text.split()\n",
    "        new_words = []\n",
    "        for word in words:\n",
    "            synonyms = []\n",
    "            for syn in wordnet.synsets(word):\n",
    "                for lemma in syn.lemmas():\n",
    "                    synonym = lemma.name().replace('_', ' ')\n",
    "                    if synonym != word:\n",
    "                        synonyms.append(synonym)\n",
    "            if len(synonyms) > 0:\n",
    "                new_words.append(np.random.choice(synonyms, n))\n",
    "            else:\n",
    "                new_words.append(word)\n",
    "        augmented_texts.append(' '.join(new_words))\n",
    "    return augmented_texts\n",
    "\n",
    "def random_insertion(texts, n=1):\n",
    "    augmented_texts = []\n",
    "    for text in texts:\n",
    "        words = text.split()\n",
    "        new_words = []\n",
    "        for word in words:\n",
    "            new_words.append(word)\n",
    "            if np.random.random() < 0.5:\n",
    "                new_words.extend([chr(np.random.randint(97, 123)) for _ in range(n)])\n",
    "        augmented_texts.append(' '.join(new_words))\n",
    "    return augmented_texts\n",
    "\n",
    "def random_deletion(texts, p=0.2):\n",
    "    augmented_texts = []\n",
    "    for text in texts:\n",
    "        words = text.split()\n",
    "        new_words = []\n",
    "        for word in words:\n",
    "            if np.random.random() > p:\n",
    "                new_words.append(word)\n",
    "        augmented_texts.append(' '.join(new_words))\n",
    "    return augmented_texts\n",
    "\n",
    "def random_swap(texts, n=1):\n",
    "    augmented_texts = []\n",
    "    for text in texts:\n",
    "        words = text.split()\n",
    "        new_words = []\n",
    "        for i in range(len(words)):\n",
    "            if np.random.random() < 0.5:\n",
    "                new_words.append(words[i])\n",
    "            else:\n",
    "                new_idx = np.random.randint(max(0, i - n), min(len(words), i + n + 1))\n",
    "                new_words.append(words[new_idx])\n",
    "        augmented_texts.append(' '.join(new_words))\n",
    "    return augmented_texts\n",
    "\n",
    "def semantic_augmentation(texts, model_name='distilbert-base-nli-mean-tokens'):\n",
    "    from transformers import pipeline\n",
    "    augmented_texts = []\n",
    "    generator = pipeline('text-generation', model=model_name)\n",
    "    for text in texts:\n",
    "        augmented_texts.append(generator(text, max_length=100, num_return_sequences=1)[0]['generated_text'])\n",
    "    return augmented_texts\n",
    "\n",
    "def mixed_augmentation(texts):\n",
    "    augmented_texts = back_translation(texts)\n",
    "    augmented_texts = synonym_replacement(augmented_texts)\n",
    "    augmented_texts = random_insertion(augmented_texts)\n",
    "    augmented_texts = random_deletion(augmented_texts)\n",
    "    augmented_texts = random_swap(augmented_texts)\n",
    "    augmented_texts = semantic_augmentation(augmented_texts)\n",
    "    return augmented_texts\n",
    "\n",
    "# Augment the training data\n",
    "X_train_augmented = mixed_augmentation(X_train)\n",
    "\n",
    "# Tokenize and pad sequences\n",
    "tokenizer = Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(X_train_augmented)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train_augmented)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=100)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=100)\n",
    "\n",
    "# Define CNN model\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Embedding(input_dim=20000, output_dim=100, input_length=100))\n",
    "cnn_model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "cnn_model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "cnn_model.add(GlobalAveragePooling1D())\n",
    "cnn_model.add(Dense(1, activation='sigmoid'))\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define LSTM model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(input_dim=20000, output_dim=100, input_length=100))\n",
    "lstm_model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "lstm_model.add(Bidirectional(LSTM(32)))\n",
    "lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define the original model\n",
    "original_model = Sequential()\n",
    "original_model.add(Embedding(input_dim=20000, output_dim=100, input_length=100))\n",
    "original_model.add(GlobalAveragePooling1D())\n",
    "original_model.add(Dense(1, activation='sigmoid'))\n",
    "original_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train and evaluate models\n",
    "cnn_model.fit(X_train_pad, y_train, epochs=10, batch_size=32, validation_data=(X_test_pad, y_test))\n",
    "lstm_model.fit(X_train_pad, y_train, epochs=10, batch_size=32, validation_data=(X_test_pad, y_test))\n",
    "original_model.fit(X_train_pad, y_train, epochs=10, batch_size=32, validation_data=(X_test_pad, y_test))\n",
    "\n",
    "# Evaluate models on test set\n",
    "cnn_test_loss, cnn_test_acc = cnn_model.evaluate(X_test_pad, y_test, verbose=0)\n",
    "lstm_test_loss, lstm_test_acc = lstm_model.evaluate(X_test_pad, y_test, verbose=0)\n",
    "original_test_loss, original_test_acc = original_model.evaluate(X_test_pad, y_test, verbose=0)\n",
    "\n",
    "print(f'CNN Test Accuracy: {cnn_test_acc}')\n",
    "print(f'LSTM Test Accuracy: {lstm_test_acc}')\n",
    "print(f'Original Model Test Accuracy: {original_test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3df6220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on test data\n",
    "y_pred_probs = model.predict(X_test_pad)\n",
    "y_pred = np.round(y_pred_probs).astype(int)  # Converting probabilities to binary output\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# ROC Curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "print(\"AUC:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4c13ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming y_test are your true labels and y_pred are your model's predictions\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc20e070",
   "metadata": {},
   "source": [
    "## Classifier Modeling (Advanced ML)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb93fc66",
   "metadata": {},
   "source": [
    "### Embeddings for Context Capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ad1c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4221a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the deduplicated DataFrame into training, testing, and validation sets\n",
    "train, test = train_test_split(df_deduplicated, test_size=0.2, random_state=42)\n",
    "train, val = train_test_split(train, test_size=0.25, random_state=42)  # 0.25 * 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faac91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive and negative sentences\n",
    "positive_sentences = train[train['Label'] == 1]['Clean_Text'].tolist()\n",
    "negative_sentences = train[train['Label'] == 0]['Clean_Text'].tolist()\n",
    "\n",
    "# Validation set sentences\n",
    "val_sentences = val['Clean_Text'].tolist()\n",
    "val_labels = val['Label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da6edfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute embeddings\n",
    "positive_embeddings = model.encode(positive_sentences, convert_to_tensor=True)\n",
    "negative_embeddings = model.encode(negative_sentences, convert_to_tensor=True)\n",
    "val_embeddings = model.encode(val_sentences, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6a7f16",
   "metadata": {},
   "source": [
    "#### Transformers for Advanced Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b7c51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarities between validation sentences and positive (ground truth) sentences\n",
    "cosine_scores_val = util.cos_sim(val_embeddings, positive_embeddings)\n",
    "\n",
    "# Convert to numpy for easier processing\n",
    "cosine_scores_val_np = cosine_scores_val.numpy()\n",
    "\n",
    "# Determine predictions based on the threshold\n",
    "def determine_predictions(scores, threshold):\n",
    "    predictions = []\n",
    "    for score_row in scores:\n",
    "        # Each row corresponds to comparisons of one validation sentence against all positive sentences\n",
    "        max_score = np.max(score_row)  # Find the max score in comparisons against positive sentences\n",
    "        predictions.append(1 if max_score >= threshold else 0)\n",
    "    return predictions\n",
    "\n",
    "# Iterate through thresholds to find the best one based on recall\n",
    "\n",
    "thresholds = np.arange(0, 1.05, 0.05)\n",
    "best_recall = 1\n",
    "best_threshold = 0.1\n",
    "for threshold in thresholds:\n",
    "    preds = determine_predictions(cosine_scores_val_np, threshold)\n",
    "    recall = recall_score(val_labels, preds)\n",
    "    if recall > best_recall:\n",
    "        best_recall = recall\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(f\"Optimal threshold: {best_threshold} with Recall: {best_recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41922aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find example sentences based on score criteria\n",
    "def find_example_sentences(scores, val_sentences, positive_sentences, criteria='high'):\n",
    "    if criteria == 'high':\n",
    "        threshold = np.max(scores) - 0.1  # Adjust as needed\n",
    "    elif criteria == 'low':\n",
    "        threshold = np.min(scores) + 0.1  # Adjust as needed\n",
    "    else:  # middle\n",
    "        threshold = np.median(scores)\n",
    "    \n",
    "    # Find index of the sentence pair that meets the criteria\n",
    "    if criteria in ['high', 'low']:\n",
    "        idx = np.argmax(scores) if criteria == 'high' else np.argmin(scores)\n",
    "        val_idx, pos_idx = np.unravel_index(idx, scores.shape)\n",
    "    else:\n",
    "        # For middle, find the closest to the median\n",
    "        abs_diff = np.abs(scores - threshold)\n",
    "        val_idx, pos_idx = np.unravel_index(np.argmin(abs_diff), scores.shape)\n",
    "    \n",
    "    return val_sentences[val_idx], positive_sentences[pos_idx], scores[val_idx, pos_idx]\n",
    "\n",
    "# Examples\n",
    "criteria_list = ['high', 'low', 'middle']\n",
    "\n",
    "for criteria in criteria_list:\n",
    "    val_sentence, pos_sentence, score = find_example_sentences(cosine_scores_val_np, val_sentences, positive_sentences, criteria)\n",
    "    print(f\"Criteria: {criteria}\")\n",
    "    print(f\"Validation Sentence: {val_sentence}\")\n",
    "    print(f\"Positive Sentence: {pos_sentence}\")\n",
    "    print(f\"Cosine Similarity Score: {score}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb669fa7",
   "metadata": {},
   "source": [
    "### Semantic Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846a7653",
   "metadata": {},
   "source": [
    "#### Adding Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45033c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_truth = pd.read_csv('Ground_Truth.csv')\n",
    "df_joined = pd.merge(df_truth, df, how='left', left_on=['Image Id', 'Body'], right_on=['img_id', 'Body'])\n",
    "df_joined = df_joined.drop_duplicates(subset=['Image Id', 'Body'], keep='first')\n",
    "\n",
    "df_joined['Body_Clean_Basics'] = df_joined['Body'].apply(clean_text)\n",
    "df_joined['Title_Clean_Basics'] = df_joined['Title'].apply(clean_text)\n",
    "\n",
    "df_joined['Body_Clean'] = df_joined['Body_Clean_Basics'].apply(lambda x: clean_text_advanced(x, \n",
    "                                                                                            method=\"lemmatization\",\n",
    "                                                                                            remove_special_chars=True, \n",
    "                                                                                            remove_numbers=False, \n",
    "                                                                                            use_custom_stopwords=False, \n",
    "                                                                                            custom_stopwords=set()))\n",
    "df_joined['Title_Clean'] = df_joined['Title_Clean_Basics'].apply(lambda x: clean_text_advanced(x, \n",
    "                                                                                            method=\"lemmatization\",\n",
    "                                                                                            remove_special_chars=True, \n",
    "                                                                                            remove_numbers=False, \n",
    "                                                                                            use_custom_stopwords=False, \n",
    "                                                                                            custom_stopwords=set()))\n",
    "\n",
    "df_joined['Clean_Text'] = df_joined['Title_Clean'].astype(str) + '\\n\\n' + df_joined['Body_Clean'].astype(str)\n",
    "df_joined['Clean_Text_Basic'] = df_joined['Title_Clean_Basics'].astype(str) + '\\n\\n' + df_joined['Body_Clean_Basics'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e96fac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_similarity(df_ground_truth, df_comparison, embedding_option, text_column_name):\n",
    "    # Load the model based on the selected embedding option\n",
    "    model = SentenceTransformer(embedding_option)\n",
    "    \n",
    "    # Generate embeddings for ground truth and comparison sentences\n",
    "    embeddings_ground_truth = model.encode(df_ground_truth[text_column_name].tolist(), convert_to_tensor=True)\n",
    "    embeddings_comparison = model.encode(df_comparison[text_column_name].tolist(), convert_to_tensor=True)\n",
    "    \n",
    "    # Compute cosine similarities between ground truth and comparison sentences\n",
    "    cosine_scores = util.cos_sim(embeddings_ground_truth, embeddings_comparison)\n",
    "    \n",
    "    # Prepare column names for similarity scores\n",
    "    similarity_columns = [f\"GT_{i}\" for i in range(len(df_ground_truth))]  \n",
    "    \n",
    "    # Convert cosine_scores to a DataFrame for easier manipulation\n",
    "    cosine_scores_df = pd.DataFrame(cosine_scores.numpy().T, columns=similarity_columns)\n",
    "    \n",
    "    # Concatenate the original comparison sentences with their similarity scores\n",
    "    results_df = pd.concat([df_comparison[[text_column_name]].reset_index(drop=True), cosine_scores_df], axis=1)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820b385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain 20 random samples from df_deduplicated\n",
    "random_samples = df_deduplicated.sample(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ed1c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function with the desired embedding option\n",
    "results_df = compare_similarity(df_joined, random_samples, 'all-MiniLM-L6-v2', 'Clean_Text')\n",
    "\n",
    "# Display the results\n",
    "if results_df is not None:\n",
    "    display(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
